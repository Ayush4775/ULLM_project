{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee276fc5",
   "metadata": {},
   "source": [
    "# General Setup\n",
    "\n",
    "This file was used to create the datasets that we used in `probing_experiments.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc04b99",
   "metadata": {},
   "source": [
    "# Generation of Initial Dataset\n",
    "The created dataset was used as training and test set for Experiment 1 and as training set for Experiment 2.  \n",
    "**Please note that rerunning the script will lead to different datasets (but with the same structure), due to the stochastic nature of the process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74067af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 1. Define placeholder pools\n",
    "# ------------------------\n",
    "names = [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\", \"Frank\", \"Grace\", \"Hank\",\n",
    "         \"Ivy\", \"Jack\", \"Kara\", \"Leo\", \"Mona\", \"Nina\", \"Oscar\", \"Paul\",\n",
    "         \"Quinn\", \"Rita\", \"Sam\", \"Tina\", \"Uma\", \"Victor\", \"Wendy\", \"Xander\",\n",
    "         \"Yara\", \"Zane\"]\n",
    "\n",
    "traits = [\"happy\", \"sad\", \"tall\", \"short\", \"kind\", \"angry\", \"brave\", \"calm\",\n",
    "          \"clever\", \"curious\", \"gentle\", \"honest\", \"lazy\", \"loud\", \"polite\",\n",
    "          \"proud\", \"quiet\", \"rude\", \"shy\", \"smart\"]\n",
    "\n",
    "# ------------------------\n",
    "# 2. Define reasoning pattern templates\n",
    "# ------------------------\n",
    "templates = {\n",
    "    \"Modus Ponens\": \"If {X} is {P}, then {Y} is {Q}. {X} is {P}. Is {Y} {Q}?\",\n",
    "    \"Modus Tollens\": \"If {X} is {P}, then {Y} is {Q}. {Y} is not {Q}. Is {X} not {P}?\",\n",
    "    \"Affirming the Consequent\": \"If {X} is {P}, then {Y} is {Q}. {Y} is {Q}. Is {X} {P}?\",\n",
    "    \"Denying the Antecedent\": \"If {X} is {P}, then {Y} is {Q}. {X} is not {P}. Is {Y} not {Q}?\"\n",
    "}\n",
    "\n",
    "validity_map = {\n",
    "    \"Modus Ponens\": \"Yes\",\n",
    "    \"Modus Tollens\": \"Yes\",\n",
    "    \"Affirming the Consequent\": \"No\",\n",
    "    \"Denying the Antecedent\": \"No\"\n",
    "}\n",
    "\n",
    "# ------------------------\n",
    "# 3. Example generator\n",
    "# ------------------------\n",
    "def generate_examples(pattern, n=500):\n",
    "    template = templates[pattern]\n",
    "    examples = set()\n",
    "\n",
    "    while len(examples) < n:\n",
    "        X, Y = random.sample(names, 2)  # ensure X != Y\n",
    "        P = random.choice(traits)\n",
    "        Q = random.choice([t for t in traits if t != P])  # avoid trivial P=Q\n",
    "        sentence = template.format(X=X, Y=Y, P=P, Q=Q)\n",
    "        examples.add(sentence)\n",
    "\n",
    "    return [{\"text_input\": s,\n",
    "             \"reasoning_class\": pattern,\n",
    "             \"validity\": validity_map[pattern]} for s in examples]\n",
    "\n",
    "# ------------------------\n",
    "# 4. Generate dataset\n",
    "# ------------------------\n",
    "dataset = []\n",
    "for pattern in templates:\n",
    "    dataset.extend(generate_examples(pattern, n=500))\n",
    "\n",
    "print(f\"Total examples generated: {len(dataset)}\")  # should be 2000\n",
    "\n",
    "# ------------------------\n",
    "# 5. Save to CSV\n",
    "# ------------------------\n",
    "csv_file = \"reasoning_patterns_dataset.csv\"\n",
    "with open(csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"text_input\", \"reasoning_class\", \"validity\"])\n",
    "    writer.writeheader()\n",
    "    for ex in dataset:\n",
    "        writer.writerow(ex)\n",
    "\n",
    "print(f\"Dataset saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930dd198",
   "metadata": {},
   "source": [
    "# Generation of OOD Test Set\n",
    "The created dataset was used as test set for experiment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25acdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities & attributes\n",
    "names = [\"Alice\", \"Bob\", \"Carol\", \"Dan\", \"Eve\"]\n",
    "traits = [\"tall\", \"happy\", \"angry\", \"hungry\", \"sleepy\"]\n",
    "\n",
    "def generate_examples(n=500):\n",
    "    data = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        X, Y = random.sample(names, 2)\n",
    "        P, Q = random.sample(traits, 2)\n",
    "\n",
    "        # Modus Ponens (valid)\n",
    "        mp = f\"Whenever {X} is {P}, subsequently {Y} is {Q}. {X} is {P}. Is {Y} {Q}?\"\n",
    "        data.append((mp, \"Modus Ponens\", \"Yes\"))\n",
    "\n",
    "        # Modus Tollens (valid)\n",
    "        mt = f\"Whenever {X} is {P}, subsequently {Y} is {Q}. {Y} is not {Q}. Is {X} {P}?\"\n",
    "        data.append((mt, \"Modus Tollens\", \"Yes\"))\n",
    "\n",
    "        # Affirming the Consequent (invalid)\n",
    "        ac = f\"Whenever {X} is {P}, subsequently {Y} is {Q}. {Y} is {Q}. Is {X} {P}?\"\n",
    "        data.append((ac, \"Affirming the Consequent\", \"No\"))\n",
    "\n",
    "        # Denying the Antecedent (invalid)\n",
    "        da = f\"Whenever {X} is {P}, subsequently {Y} is {Q}. {X} is not {P}. Is {Y} {Q}?\"\n",
    "        data.append((da, \"Denying the Antecedent\", \"No\"))\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"text_input\", \"reasoning_class\", \"validity\"])\n",
    "\n",
    "# Generate dataset\n",
    "df_test = generate_examples(500)\n",
    "\n",
    "# Save\n",
    "df_test.to_csv(\"reasoning_patterns_test_whenever.csv\", index=False)\n",
    "print(\"Test dataset generated with whenever/subsequently phrasing (2000 rows)!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
